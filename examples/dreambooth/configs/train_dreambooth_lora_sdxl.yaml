# Path to pretrained model or model identifier from huggingface.co/models
pretrained_model_name_or_path: stabilityai/stable-diffusion-xl-base-0.9

# Path to pretrained VAE model with better numerical stability. More details: https://github.com/huggingface/diffusers/pull/4038
pretrained_vae_model_name_or_path: null

# Revision of pretrained model identifier from huggingface.co/models
revision: null

# A folder containing the training data of instance images
instance_data_dir: INSTANCE_DIR

# A folder containing the training data of class images
class_data_dir: null

# The prompt with identifier specifying the instance
instance_prompt: A photo of sks dog

# The prompt to specify images in the same class as provided instance images
class_prompt: null

# A prompt that is used during validation to verify that the model is learning
validation_prompt: null

# Number of images that should be generated during validation with `validation_prompt`
num_validation_images: 4

# Run dreambooth validation every X epochs. Dreambooth validation consists of running the prompt `args.validation_prompt` multiple times: `args.num_validation_images`
validation_epochs: 50

# Flag to add prior preservation loss
with_prior_preservation: false

# The weight of prior preservation loss
prior_loss_weight: 1.0

# Minimal class images for prior preservation loss. If there are not enough images already present in class_data_dir, additional images will be sampled with class_prompt
num_class_images: 100

# The output directory where the model predictions and checkpoints will be written
output_dir: "lora-dreambooth-model"

# A seed for reproducible training
seed: null

# The resolution for input images, all the images in the train/validation dataset will be resized to this resolution
resolution: 512

# Coordinate for (the height) to be included in the crop coordinate embeddings needed by SDXL UNet
crops_coords_top_left_h: 0

# Coordinate for (the height) to be included in the crop coordinate embeddings needed by SDXL UNet
crops_coords_top_left_w: 0

# Whether to center crop the input images to the resolution. If not set, the images will be randomly cropped. The images will be resized to the resolution first before cropping
center_crop: false

# Whether to train the text encoder. If set, the text encoder should be float32 precision
train_text_encoder: false

# Batch size (per device) for the training dataloader
train_batch_size: 1

# Batch size (per device) for sampling images
sample_batch_size: 4

# Number of training epochs
num_train_epochs: 1

# Total number of training steps to perform.  If provided, overrides num_train_epochs
max_train_steps: null

# Save a checkpoint of the training state every X updates. These checkpoints can be used both as final checkpoints in case they are better than the last checkpoint, and are also suitable for resuming training using `--resume_from_checkpoint`
checkpointing_steps: 500

# Max number of checkpoints to store
checkpoints_total_limit: null

# Whether training should be resumed from a previous checkpoint. Use a path saved by `--checkpointing_steps`, or `"latest"` to automatically select the last available checkpoint
resume_from_checkpoint: null

# Number of updates steps to accumulate before performing a backward/update pass
gradient_accumulation_steps: 1

# Whether or not to use gradient checkpointing to save memory at the expense of slower backward pass
gradient_checkpointing: false

# Initial learning rate (after the potential warmup period) to use
learning_rate: 0.0005

# Scale the learning rate by the number of GPUs, gradient accumulation steps, and batch size
scale_lr: false

# The scheduler type to use. Choose between ["linear", "cosine", "cosine_with_restarts", "polynomial", "constant", "constant_with_warmup"]
lr_scheduler: "constant"

# Number of steps for the warmup in the lr scheduler
lr_warmup_steps: 500

# Number of hard resets of the lr in cosine_with_restarts scheduler
lr_num_cycles: 1

# Power factor of the polynomial scheduler
lr_power: 1.0

# Number of subprocesses to use for data loading. 0 means that the data will be loaded in the main process
dataloader_num_workers: 0

# Whether or not to use 8-bit Adam from bitsandbytes
use_8bit_adam: false

# The beta1 parameter for the Adam optimizer
adam_beta1: 0.9

# The beta2 parameter for the Adam optimizer
adam_beta2: 0.999

# Weight decay to use
adam_weight_decay: 0.01

# Epsilon value for the Adam optimizer
adam_epsilon: 0.00000001

# Max gradient norm
max_grad_norm: 1.0

# Whether or not to push the model to the Hub
push_to_hub: false

# The token to use to push to the Model Hub
hub_token: null

# The name of the repository to keep in sync with the local `output_dir`
hub_model_id: null

# [TensorBoard](https://www.tensorflow.org/tensorboard) log directory. Will default to *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***
logging_dir: "logs"

# Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices
allow_tf32: false

# The integration to report the results and logs to. Supported platforms are `"tensorboard"` (default), `"wandb"` and `"comet_ml"`. Use `"all"` to report to all integrations
report_to: "tensorboard"

# Whether to use mixed precision. Choose between fp16 and bf16 (bfloat16). Bf16 requires PyTorch >= 1.10.and an Nvidia Ampere GPU.  Default to the value of accelerate config of the current system or the flag passed with the `accelerate.launch` command. Use this argument to override the accelerate config
mixed_precision: null

# Choose prior generation precision between fp32, fp16 and bf16 (bfloat16). Bf16 requires PyTorch >= 1.10.and an Nvidia Ampere GPU.  Default to  fp16 if a GPU is available else fp32
prior_generation_precision: null

# For distributed training: local_rank
local_rank: -1

# Whether or not to use xformers
enable_xformers_memory_efficient_attention: false